{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "739f5d86",
   "metadata": {},
   "source": [
    "## âœ… Roadmap del Proyecto de Web Scraping y Carga a Base de Datos\n",
    "\n",
    "Este proyecto tiene como objetivo scrapear libros desde una web pÃºblica, obtener informaciÃ³n adicional mediante una API externa y almacenar los datos en una base de datos relacional para su posterior anÃ¡lisis.\n",
    "\n",
    "### ðŸ› ï¸ Etapas del desarrollo\n",
    "\n",
    "- [ ] **1. Web Scraping**\n",
    "  - [x] Scrapear todos los gÃ©neros desde la pÃ¡gina principal.\n",
    "  - [x] Iterar sobre cada gÃ©nero para obtener todos los libros listados.\n",
    "  - [ ] Extraer tÃ­tulo, precio, stock, rating y link a la pÃ¡gina del libro.\n",
    "  - [ ] Extraer informaciÃ³n detallada desde la pÃ¡gina de cada libro (si es necesario).\n",
    "  - [ ] Consultar la API de Google Books para obtener el autor y mÃ¡s detalles (usando el tÃ­tulo).\n",
    "  - [ ] Guardar los datos obtenidos en archivos `.csv` separados:\n",
    "    - [ ] Libros (`libros.csv`)\n",
    "    - [ ] Autores (`autores.csv`)\n",
    "    - [ ] GÃ©neros (`generos.csv`)\n",
    "\n",
    "- [ ] **2. ValidaciÃ³n**\n",
    "  - [ ] Verificar la integridad y limpieza de los datos descargados.\n",
    "  - [ ] Eliminar duplicados y manejar valores nulos si los hay.\n",
    "\n",
    "- [ ] **3. DiseÃ±o de Base de Datos Relacional**\n",
    "  - [ ] Crear script DDL:\n",
    "    - [ ] Crear la base de datos (si no existe).\n",
    "    - [ ] Crear las tablas `libros`, `autores`, `generos`, y tablas intermedias para relaciones N:N si aplica.\n",
    "  - [ ] Crear diagrama UML/ER para visualizar relaciones.\n",
    "\n",
    "- [ ] **4. InserciÃ³n de Datos**\n",
    "  - [ ] Crear script DML para insertar los datos desde los CSV a la base de datos (usando Python + `psycopg2` o `SQLAlchemy` para PostgreSQL).\n",
    "  - [ ] Comprobar inserciones correctas mediante queries de prueba.\n",
    "\n",
    "- [ ] **5. Consultas y AnÃ¡lisis**\n",
    "  - [ ] Escribir consultas SQL para:\n",
    "    - [ ] Obtener todos los libros por gÃ©nero.\n",
    "    - [ ] Buscar libros por autor.\n",
    "    - [ ] Calcular estadÃ­sticas como precio promedio por gÃ©nero o autor.\n",
    "  - [ ] (Opcional) Crear una vista para simplificar reportes.\n",
    "\n",
    "---\n",
    "\n",
    "> ðŸ“Œ **Nota:** La base de datos serÃ¡ inicialmente verificada con SQLite por simplicidad, luego se adaptarÃ¡ a PostgreSQL para una implementaciÃ³n mÃ¡s robusta con PgAdmin.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161a70a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install BeautifulSoup4\n",
    "!pip install sqlalchemy psycopg2-binary pandas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b5e8fe",
   "metadata": {},
   "source": [
    "lista generos\n",
    "lista linklibro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5e9edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import web grabbing client and\n",
    "# HTML parser\n",
    "from urllib.request import urlopen as uReq\n",
    "from bs4 import BeautifulSoup as soup\n",
    "\n",
    "# variable to store website link as string\n",
    "myurl = 'http://books.toscrape.com/index.html'\n",
    "\n",
    "# grab website and store in variable uclient\n",
    "uClient = uReq(myurl)\n",
    "\n",
    "# read and close HTML para no sobrecargar de pedidos\n",
    "page_html = uClient.read()\n",
    "uClient.close()\n",
    "\n",
    "# call BeautifulSoup for parsing\n",
    "page_soup = soup(page_html, \"html.parser\")\n",
    "\n",
    "# grabs all the products under list tag\n",
    "bookshelf = page_soup.find(\n",
    "    \"ul\", {\"class\": \"nav nav-list\"})\n",
    "links = bookshelf.findAll(\"a\")\n",
    "\n",
    "filename = (\"Genero.csv\")\n",
    "f = open(filename, \"w\")\n",
    "\n",
    "headers = \"Gender title\\n\"\n",
    "f.write(headers)\n",
    "\n",
    "lista_genero= []\n",
    "i=0\n",
    "for link in links:\n",
    "    if i != 0:\n",
    "        # collect link of all genders\n",
    "        a = link.get(\"href\")\n",
    "        genero = link.get_text()\n",
    "        lista_genero.append(a)\n",
    "        f.write(genero+ \"\\n\")\n",
    "    i=i+1 # just to ignore the first\n",
    "f.close()\n",
    "\n",
    "titulos = (\"Titulos.csv\")\n",
    "f = open(titulos, \"w\")\n",
    "headers = \"Titulos\\n\"\n",
    "f.write(headers)\n",
    "\n",
    "lista_libro = [] \n",
    "\n",
    "for genero in lista_genero:\n",
    "    f.write( \"Genero xx\\n\")\n",
    "    uGender = uReq(\"https://books.toscrape.com/\"+genero)\n",
    "    pagina_libro = uGender.read()\n",
    "    uGender.close()\n",
    "\n",
    "    gender_soup = soup(pagina_libro, \"html.parser\")\n",
    "    libro = gender_soup.find_all(\"li\", {\"class\": \"col-xs-6 col-sm-4 col-md-3 col-lg-3\"})\n",
    "    for i in libro:\n",
    "        direccion = i.select(\"h3 > a\")#iterar los libros\n",
    "        lista_libro.append(direccion)\n",
    "        for j in direccion:\n",
    "            f.write(j.get_text() + \"\\n\")\n",
    "f.close()\n",
    "\n",
    "lista_autor= [] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34cc3046",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
